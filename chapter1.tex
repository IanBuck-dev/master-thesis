% -----------------------------------------------------------------------
% -----------------------------------------------------------------------

\chapter{Introduction}
\label{chap:Introduction}
% 4 pages in total

In 2023 56\% of the human population already lives in urban areas with the number projected to continiously increase to 68\% by 2050 \footnote{https://ourworldindata.org/urbanization\#by-2050-more-than-two-thirds-of-the-world-will-live-in-urban-areas}. Combined with the ongoing climate change and urban densification due to the need for more and more living space, cities are facing many new challenges. With the removal of vegetation in favor of living space and the sealing of surfaces with heat-absorbing materials such as asphalt or concrete for streets and highways~\cite{gret2020urban}, rising temperatures lead to new phenomena that pose risks for the urban citizens. One especially critical phenomenon is the urban heat-island (UHI). A UHI is a local occurrence of higher temperatures than surrounding rural areas that pose health risks, especially for the elderly, children or citizen with prior health-issues~\cite{martin2015alternative}, pedestrians comfort, and other city-related topics such as water- and energy-management. The research topic of UHI's has seen a huge amount of contributions in the last two decades, but according to Steward, \textit{controlled measurement} and \textit{openness of method} are still two mayor areas of weakness~\cite{stewart2011systematic}, that are related to difficulties in taking measurements in urban areas~\cite{oke2006guideline} and a lack of rigorous methodology.\\
There are two mayor approaches to measure the temperature of a city. The first approach is to use satellites to measure Land Surface Temperature (LST). While allowing for an analysis of large areas without the need of ground weather-stations, this approach comes with certain downsides, such as low temporal and spatial resolution and restrictions such as only being able to measure temperatures when no clouds interfere with the microwaces send from the measuring satellite~\cite{zhang2015estimation}. The exact spatial and temporal resolution depends on the type of satellite used, with usual spatial resolutions ranging from 1km$^2$ to 5km$^2$ and usual temporal resolutions ranging from daily to monthly temperature values~\cite{ghent2022esalst}, however these resolutions are not enough to capture the microclimate of a city~\cite{voelkel2017towards}.\\
In comparison, traditional meterological observation networks, such as the German Weather Service (DWD), offer a much higher temporal resolution at 10min intervals through the use of ground weather stations, however they are usually only available at very low spatial resolutions, as they are used to monitor the climate at a meso-scale level. Additionally, the placement of these stations is usually not optimized for the detection of UHI's, as they are commonly placed near to airports that are not located directly in the city center. They can however be used as reference stations to get an idea about the boundaries of the climate inside a city as they offer high quality data by using high quality reference sensors and follow WHO guidelines~\cite{oke2006guideline}.\\
Lastly, there is the possibility of deploying sensor networks to closely monitor the climate of the city. These sensor networks can either be deployed professionally by the city itself or research projects for a limited time period, in that case called testbeds, or they can be deployed by citizens themselves, in that case called citizen-owned sensor networks or private weather station networks (PWS) in the case of crowd-sensing meterological data. Well-known examples of professionally setup testbeds include the Birmingham Urban Climate Laboratory (BUCL)~\cite{chapman2015birmingham} and the Helsinki Testbed~\cite{koskinen2011helsinki} that usually focus on measuring meso-scale weather phenomena and are very costly to run and maintain.
PWS networks can either be run by citizens themselves, such as the Sensor.Community~\footnote{\url{https://deutschland.maps.sensor.community/}} project, or by companies, such as Netatmo~\footnote{\url{https://weathermap.netatmo.com/}}, however citizens are always responsible for the placement and maintenance of the individual sensors. Due to the lack of quality control, the data quality of these networks is usually not as high as the data quality of professional networks and require special data quality control (QC) steps~\cite{fenner2021crowdqc+, meier2017crowdsourcing}, however they offer a much higher spatial resolution and can be used to gain insights into the microclimate of a city. Recently, there have been efforts to combine the data from PWS networks, mainly from Netatmo, Wundermap, and Weather Underground, with data from national weather services, such as the DWD, to improve weather prediction quality. The main collaboration network in this area is EUMETNET which includes 31 european national meteorological services~\cite{hahn2022observations}.\\
While these different approaches offer different advantages and disadvantages of measuring air temperature (TA) on the ground, they all have one thing in common: they only offer point measurements of the temperature at the location of the sensor. To get an overview of the temperature distribution across a city, interpolation methods are needed to create a continuous data-layer from the point measurements.

\section{Objective}

As research realted activities commonly rely on continuous or gridded data fields, there needs to be a way to convert these single data points from the different sensors into a continuous data-layer.\\
In this paper, we propose a solution to this problem by training a machine learning regression model, that allows for the interpolation of missing data-points. Based on sensor readings, from the sensor networks and mobile sensors, of commonly collected weather information, such as temperature, humidity, rain, pressure, wind, and possibly other variables such as vegetation indexes \cite{alonso2020new}, the model then creates a continuous data-layer that allows for a holistic view of the observed variable, in this case temperature.\\

current situation: abundance of data (data quality unknown), but different data sources at different places with different formats, making it hard to work with different sources at the same time
- smart city example -> heat island detection
    - sensor networks (statinary + mobile)
    - LST satellite data (lack of spatiotemporal resolution, not suited for micro-climate)
    - vegetation indexes (in geoinformation systems/portals)
    - etc.
- currently these sources are used independently from each other, but how can they be integrated?
    - hybrid approaches have shown that combining different approaches (smart city stationary + moving sensors) to give better prediction quality than singular approach (reasons: unobserved areas)
    - statistical models offer not enough flexibility/are to cumbersom to work with (and probabilities are not known)
    - ML is a good fit to analyse patterns and rules
        - but effort to retrain models for each application expensive
- how can ML be used to integrate the different types of data?
- how can data availibility of contexttual data be improved by leveraging ML approaches for different topics?
    - for the heat map detection, what you need is a fine-granular temperature map, that allows for outlier detection
        - either train your own model on a huge dataset
        - or access a temperature map -> this will be discussed, how to use ML for this and improve data availibilty by using interpolation
- additonal topics to briefly discuss (mainly apply by implementing ML models) 
    - what work needs to be done before using the data in ML (preprocessing, transformation, outlier detection etc.)
        - one way of preparing data is to interpolate missing data to create continous gridded features (focus of this work)
        - how ML can we improve the interpolation quality of features? -> turn sparse features into denser versions with interpolation, interpolation based on other features present

Methodology

In order to validate these things, we need high quality data-sets with many different features, but there are not many available, even tho for certain things (atmosphere etc.) there are OpenData sets available.
Goal is: implement a temperature map based on ML that interpolates missing data based on historical and current data.
Compare prediction quality of different type of models (DL, random forests etc.) based on cross-validation (simulate missing data by leaving data points out on purpose) -> experiment with different intervals, densities etc. -> could also compare to Krigin (as a typical geostatistical approach for temperature interpolation)
Subgoal: In order to achive this, we also need high quality data-sets to train and validate the model -> source them from OpenData platforms

Forschungsfragen:
- Which machine learning-based interpolation methods are available and how do they differ from each other?
- How can machine learning-based interpolation methods be used in the context of UHI detection and how do they perform compared to each other?

\section{Structure of this work}

Research methods:\\
- literature research as foundation\\
    - heat island detection
        - smart cities -> sensor networks vs LST
        - what type of other data is available? geoinformation, vegetatition, for micro-climate: shades of bigger buildings?
    - 
- prototyping\\
    - implement pipeline to pre-process different types of data\\
    - feature extraction\\
    - implement ML model\\
    - deploy ML model\\
\\
- create/search for fine granular data sets\\
    - add new contextual data to exitsing data sets\\
    - discuss different types of data (gridded vs continous vs data points) and methods for each
\\
- train ML models with different methods (deep learning, random forests etc.) and different features enabled\\
\\
- cross validation of results\\
    - discuss validation techniques and indicators (RSME, MSE)\\


% Strucure of the thesis
The rest of the thesis is structured as follows. Chapter \ref{chap:Related Work} begins with an analysis of related work, where important literature is discussed, that forms the foundation of this research. In chapter \ref{chap:System Architecture}, the focus lies on describing the service architecture, that shows how a machine learning model can be deployed in different contexts to improve data availability. Which machine learning approaches can be used to interpolate missing data and how they differ from each other is discussed in chapter \ref{chap:Machine Learning based Interpolation}. In Chapter \ref{chap:Evaluation}, the different ML approaches are compared and cross validated with each other based on the different model that are trained on the obtained data-sets. Finally, chapter \ref{chap:Conclusion} discusses the findings of this thesis and gives an outlook into future work and research directions.
